Answer Following Questions in detail.


1. What is Machine Learning ? 
	Ans. Machine learning is an application of artificial intelligence (AI) that provides systems with the ability to automatically learn and improve from experience without being explicitly programmed. Machine learning focuses on the development of computer programs that can access data and use it to learn for themselves.
The process of learning begins with observations or data, such as examples, direct experience, or instructions, in order to look for patterns in data and make better decisions in the future based on the examples that we provide. The primary aim is to allow the computers to learn automatically without human intervention or assistance and adjust their actions accordingly.

2. What is Data Science ? 
	Ans. Dealing with unstructured and structured data, Data Science is a field that encompasses anything related to data cleansing, preparation, and analysis. Put simply, Data Science is an umbrella term for techniques used when trying to extract insights and information from data. Data scientists combine statistics, mathematics, programming, problem-solving, capturing data in ingenious ways, the ability to look at things differently to find patterns, along with the activities of cleansing, preparing, and aligning the data. 

3. What is Data Mining ? 
	Ans. Data mining is the process of sorting through large data sets to identify patterns and establish relationships to solve problems through data analysis. Data mining tools allow enterprises to predict future trends. 
In data mining, association rules are created by analyzing data for frequent if/then patterns, then using the support and confidence criteria to locate the most important relationships within the data. Support is how frequently the items appear in the database, while confidence is the number of times if/then statements are accurate.
Other data mining parameters include Sequence or Path Analysis, Classification, Clustering and Forecasting. Sequence or Path Analysis parameters look for patterns where one event leads to another later event. A Sequence is an ordered list of sets of items, and it is a common type of data structure found in many databases. A Classification parameter looks for new patterns, and might result in a change in the way the data is organized. Classification algorithms predict variables based on other factors within the database.

4. What is Data Analytics ? 
Ans. Data Analytics is the science of examining raw data with the purpose of finding patterns and drawing conclusions about that information by applying an algorithmic or mechanical process to derive insights.


5. What are the tools used for the Data Mining ?
	Ans. Data mining techniques are used in many research areas, including mathematics, cybernetics, genetics and marketing. While data mining techniques are a means to drive efficiencies and predict customer behavior, if used correctly, a business can set itself apart from its competition through the use of predictive analysis.
Web mining, a type of data mining used in customer relationship management, integrates information gathered by traditional data mining methods and techniques over the web. Web mining aims to understand customer behavior and to evaluate how effective a particular website is.
Other data mining techniques include network approaches based on multitask learning for classifying patterns, ensuring parallel and scalable execution of data mining algorithms, the mining of large databases, the handling of relational and complex data types, and machine learning. Machine learning is a type of data mining tool that designs specific algorithms from which to learn and predict.


6. Explain the Limitations of the tools which you have listed in the above questions answer.
Ans.
      R-Programming tool: R is a slow programming language: this tends to be one of the recurrent complaints mentioned by developers when asked about the drawbacks of programming with R. The quality of some packages is less than perfect, although if a package is useful to many people, it will quickly evolve into a very robust product through collaborative efforts. Python : Python doesn't have good documentation: some programmers complain about the lack of good documentation for Python, particularly compared to other programming languages like PHP and Java. Knime: No intermediate results, no interactive execution , Not all nodes can be streamed. WEKA: It is sometimes difficult to compare the quality of the clusters produced. It is difficult to fix the actual value of k. It does not work well with non-globular clusters. Rapid Miner (erstwhile YALE): No coding required-Challenging to use for coders. Although it does contain Java/Python modules you must use flow programming interface. Commercial- Expensive licenses need to be purchased. Unintuitive- Its very easy to get lost in the sea of modules Limited- Its use case is limited to the set of processors/modules it contains. 7.What are the tasks in the Machine Learning ?
All of the Machine Learning algorithms take data as input, but what they want to achieve is different. They can be broadly be classified in a few groups based on the task they are designed to solve. These tasks are: classification, regression and clustering.
Classification If we have data, say pictures of animals, we can classify them. This animal is a cat, that animal is a dog and so on. A computer can do the same task using a Machine Learning algorithm that’s designed for the classification task. In the real world, this is used for tasks like voice classification and object detection. This is a supervised learning task, we give training data to teach the algorithm the classes they belong to.
Regression Sometimes you want to predict values. What are the sales next month? What is the salary for a job? Those type of problems are regression problems. The aim is to predict the value of a continous response variable. This is also a supervised learning task
Clustering Clustering is to create groups of data called clusters. Observations are assigned to a group based on the algorithm. This is an unsupervised learning task, clustering happens fully automatically. Imagining have a bunch of documents on your computer, the computer will organize them in clusters based on their content automa

8.Give at least 5 examples of the tasks which you have given in above question.
Ans.Regression: stimation of housing price, product price, stock price: customer segmentation, product features identification for product roadmap Classification: predicting whether or not an email if spam Clustering
9.Do a research of what is the impact of Machine Learning on the society?
Ans.Machine learning, also known as Analytics 3.0, is the latest development in the field of data analytics. Machine learning allows computers to take in large amounts of data, process it, and teach themselves new skills using that input. It’s a way to achieve artificial intelligence, or AI, using a “learn by doing” process. Machine learning enables computers to learn and act without being explicitly programmed. It evolves from the study of pattern recognition and the design and analysis of algorithms to enable learning from data and make possible data-driven predictions or decisions. It is so pervasive today that many of us likely use it several times a day without even knowing it.
Key Considerations and Implications
The moral component — The level of intelligence and “morality” that a machine exerts is a direct result of the data it receives. One consequence is that, based on the data input, machines may train themselves to work against the interest of some humans or be biased. Failure to erase bias from a machine algorithm may produce results that are not in line with the moral standards of society. Yet not all researchers, scientists and experts believe that AI will be hurtful to society. Some believe that AI can be developed to mirror the human brain and obtain human moralistic psychology to enhance society.
Accuracy of risk assessments — Risk assessments are used in many areas of society to evaluate and measure the potential risks that may be involved in specific scenarios. The increasing popularity of using AI risk assessments to make important decisions on behalf of people is a direct result of the growing trust between humans and machines. However, there are serious implications to note when using a machine learning system to make risk assessments. A quantitative analyst estimates that some machine learning strategies may fail up to 90 percent when tested in a real-life setting. The reason is that while algorithms used in machine learning are based on an almost infinite amount of items, much of this data is very similar. For these machines, finding a pattern would be easy, but finding  a pattern that will fit every real-life scenario would be difficult.
Transparency of algorithms —Supporters of creating transparency in AI advocate for the creation of a shared and regulated database that is not in possession of any one entity that has the power to manipulate the data; however, there are many reasons why corporations are not encouraging this. While transparency may be the solution to creating trust between users and machines, not all users of machine learning see a benefit there.

10.Research for privacy and machine learning.
Ans.Since the dawn of big data, privacy concerns have overshadowed every advancement and every new algorithm. This is the same for machine learning, which learns from big data to essentially think for itself. This presents an entirely new threat to privacy, opening up volumes of data for analysis on a whole new scale. Many standard applications of machine learning and statistics will, by default, compromise the privacy of individuals represented in the data sets. They are also vulnerable to hackers, who would edit the training data, compromising both the data and the final goal of the algorithm. A recent project that demonstrates how machine learning could directly be used in the invasion of privacy was carried out by researchers at Cornell Tech in New York. Ph.D. candidate, Richard McPherson, Professor Vitaly Shmatikov, and Reza Shokri applied basic machine learning algorithms - not even specifically written for the purpose - to identify people in blurred and pixelated images. In tests where humans had no chance of identifying the person (0.19%), they say the algorithm had 71% accuracy. This went up to 83% when the computer was given five opportunities. Blurred and pixelated images have long been used to disguise people and objects. License plate numbers are routinely blurred on television, as well as the faces of underage criminals, victims of particularly horrific crimes and tragedies, and those wishing to remain anonymous when interviewed. YouTube even offers its own facial blurring tool, developed to mask protestors and prevent potential retribution. What’s possibly the most shocking part of the research is the ease with which the researchers were able to make it work. The team used mainstream machine learning methods where the computer is trained with a set of example data rather than programming. McPherson noted that, ‘One was almost a tutorial, the first one you download and play with when you’re learning neural nets.’ They also noted that the training data could be as simple as images on Facebook or a staff directory on a website. For numbers and letters (even handwritten), the training data is publicly available online, opening up the further risk of fraud.
